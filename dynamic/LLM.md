# LLM

本文介绍了一些LLM的测试数据，我使用的LLM以及使用体验。

### 模型测试数据

这部分收录了一些LLM在常见的测试集的测试结果，只收录同规模下最优秀的模型。

旗舰模型和推理模型：

| Model | AIME2024 | AIME2025 | GPQA Diamond | Codeforces(rating) | LiveCodeBench | SWE-Bench | Humanity’s Last Exam | Frontier Math |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 非推理模型 |  |  |  |  |  |  |  |  |
| Deepseek v3 0324 | 59.4 |  | 68.4 |  | 49.2 |  |  |  |
| Grok3 | 52 |  | 75 |  | 57 |  |  |  |
| Grok3 mini | 40 |  | 65 |  | 41 |  |  |  |
| GPT4.1 | 48.1 |  | 66.3 |  |  | 55 |  |  |
| GPT4.1 Mini | 49.6 |  | 65 |  |  | 24 |  |  |
| Claude 3.7 Sonnet | 23.3 |  | 68 |  |  | 62.3(70.3) |  |  |
| 推理模型 |  |  |  |  |  |  |  |  |
| Qwen3 4b | 73.8 | 65.6 | 55.9 | 1671 | 54.2 |  |  |  |
| Phi4 reasoning plus |  | 78 | 69.3 | 1936 | 60.6 |  |  |  |
| Qwen3 30b a3b | 80.4 | 70.9 | 65.8 | 1974 | 62.6 |  |  |  |
| Qwen3 235b a22b | 85.7 | 81.5 |  | 2056 | 70.7 |  |  |  |
| Gemini 2.5 Flash exp | 88 |  | 78.3 |  | 63.5 |  | 12.1 |  |
| OpenAI o4 mini | 93.4 |  | 81.4 | 2719 |  | 68.1 | 14.3 | 17 |
| Grok3 mini Reasoning | 90（96） |  | 81（84） |  | 75（80） |  |  | 6 |
| Claude 3.7 Sonnet（thinking） | 61.3(80.0) |  | 78.2(84.8) |  |  |  | 8.9 | 4 |
| Gemini2.5 pro exp | 92 |  | 84 |  | 70.4 | 63.8 | 18.8 |  |
| Skywork R1V2 38b | 78.9 |  |  |  | 63.6 |  |  |  |

多模态模型：

| Model | MMLU | MMNU-Pro | ChartQA | DocVQA | OCRBench | AI2D | MathVista | MathVision  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 非推理模型 |  |  |  |  |  |  |  |  |
| Doubao 1.5pro | 73.8 |  | 88 | 96.7 |  |  | 78.8 |  |
| GPT4.1 | 75 |  |  |  |  |  | 72 |  |
| GPT4.1 Mini | 73 |  |  |  |  |  | 73 |  |
| Claude-3.5-Sonnet | 72 | 54.7 | 90.8 | 94.2 | 790 | 82 | 65.4 | 38.3 |
| Gemini2.0 Flash | 70.6 | 57 | 88.3 | 92.9 | 846 | 85.1 | 73.1 | 41.3 |
| Qwen2.5 VL 32B | 70 | 49.5 |  | 94.8 |  |  | 74.7 |  |
| Kimi VL 16b a3b | 57 |  |  |  | 867 | 84.9 | 68.7 | 21.4 |
| InternVL3 8B | 65.6 |  | 86.6 | 92.7 | 880 | 85.2 | 75.2 |  |
| 推理模型 |  |  |  |  |  |  |  |  |
| OpenAI o4 mini | 81.6 |  |  |  |  |  | 84.4 |  |
| Kimi VL Thinking 16b a3b | 61.7 |  |  |  |  |  | 71.3 | 36.8 |
| Skywork R1V2 38b | 73.6 | 52 |  |  |  |  | 74 | 49 |

无审查模型：

这类模型比较少没有专门的测试数据，通常与基底模型接近，目前Dolphin3系列比较完善，也可以选择最新模型的去对齐版本。

### 模型推理

##### 推理框架
1.Transformers兼容性强，但优化较差。\
2.Ollama基于llama.cpp，稳定性和显存优化较好，但对多模态模型的支持比上游慢。\
3.LM Studio同样基于llama.cpp，兼容性与上游一致，提供图形界面并集成RAG功能。\
4.VLLM注重张量并行和并发优化。\
5.KTransformer注重异构计算，长上下文和并发速度相比CPU部署有一定优势。

##### 本地部署情况

考虑模型适配和自带界面，我选择了LM Studio。我的电脑配置为3070m+5600h+双通道ddr4 3200。

部署情况如下：\
1.Qwen3 8b和Qwen3 30b a3b用于通用任务。\
2.Qwen2.5 VL 7b用于多模态任务。\
3.Dolphin3.0 Llama3 8b用于无审查任务。

##### api使用情况

我个人偏向开源模型，使用的api如下：\
1.Deepseek api，使用Deepseek模型，因为其模型在开源模型中比较优秀，成本也不太高。\
2.Siliconflow api，以前Deepseek api繁忙时用于Deepseek模型，目前主要用于Qwen模型。主要优势是方便使用不同厂商的模型。\
3.Openrouter api，主要使用免费模型，提供Dolphin3等无审查模型相比国内api也有优势。

##### 使用体验

1.在编程任务上，目前的LLM还是只适合相对简单的程序，在复杂程序、中大型项目以及功能细节不确定的程序上表现较差，更适合Python等语法简洁的编程语言。\
2.在对话和写作上，Deepseek R1以及其它对其进行蒸馏的模型解决了之前的模型过于形式化的问题，散文写作这文学性也有提升，但其它时候容易过度使用科技元素。\
3.成本方面，个人偏向小型项目成本3元以内，Deepseek R1已经接近上限了，如果有比较好的小参数量模型还是会有一定优势。