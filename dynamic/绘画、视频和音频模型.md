# 绘画、视频和TTS模型

### 绘画模型

综合来看比较有优势的开源绘画模型是PixelWave Flux.1 dev，提高了Flux.1 dev的光照和材质表现但复杂场景中没有提升，案例位于 https://william7004-new-gallery.streamlit.app/Pixelwave

闭源的GPT4o和开源的Lumina mGPT 2.0包含使用自然语言的图像生成和编辑功能，后者部署门槛较高。OmniGen和Flex.2 Preview等模型也集成了一些编辑功能。

其它使用案例：
1. cogview4: https://william7004-gallery.streamlit.app/AI%E5%9B%BE%E7%89%87
2. Hunyuan Video:  https://william7004-hunyuan-video-gallery.streamlit.app/%E5%9B%BE%E7%89%87

### 视频模型

闭源视频模型中Veo2和可灵2.0等模型效果好但成本也较高，可灵1.6的成本低一些。

开源视频模型功能上有不同侧重点

侧重功能性：
1. FramePack改进了Hunyuan Video的图生视频版本，使用从尾帧开始分段生成的方法，降低了生成长视频的显存占用，非固定场景建议把生成长度控制在4秒，固定场景可以生成60秒。
2. Skyreels V2改进了Wan2.1系列，可以通过多次推理生成连续的长视频，也实现了1.3b版本的图生视频。
3. Wan2.1 1.3b VACE实现了参考图和视频编辑等功能，在3070m生成1088x608分辨率视频单帧要16.3秒，目前的预览版在参考图角度调整等方面表现不太好，画质和出片率低于原版。使用案例位于 https://william7004-new-gallery.streamlit.app/Wan2.1_VACE 。

侧重速度：
1. Ltx Video 0.9.6版本效果有一定提升，具有较大的成本优势但只适合静态场景或汽车题材的图生视频，人物可以用半身图片但容易变形，另外生成时画面不太稳定。由于高分辨率下运动效果和画质下降，建议使用1088x608分辨率，另外需要适当降低最大移位以减少强行分镜的情况。
2. Fast Hunyuan需要搭配对应的lora才能正常使用，画质略低于原版，稳定性和适用范围优于LTX Video，8步生成1136x640视频在3070m单帧用时8.3秒。使用案例位于 https://william7004-new-gallery.streamlit.app/FastHunyuan 。

其它使用案例：
1. Hunyuan Video:  https://william7004-hunyuan-video-gallery.streamlit.app/%E8%A7%86%E9%A2%91
2. Wan2.1 14b： https://william7004-new-gallery.streamlit.app/AI%E8%A7%86%E9%A2%91
3. Wan2.1 1.3b：https://william7004-gallery.streamlit.app/AI%E8%A7%86%E9%A2%91 

### 音频模型

##### TTS模型

由于没有推理框架，我用过的TTS模型不多，目前主要使用FishTTS，使用案例位于 https://william7004-gallery.streamlit.app/LLM%E6%95%A3%E6%96%87%E9%9B%86

##### 音乐模型

YuE算是第一个可用的开源音乐模型，逻辑达到可用水平但音质比较差，使用案例位于 https://william7004-gallery.streamlit.app/LLM%E6%9F%A5%E8%AF%A2 