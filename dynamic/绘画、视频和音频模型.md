# 绘画、视频和TTS模型

### 绘画模型

##### 桌面设备

目前最好的开源绘画模型是HiDream i1 full，细节与优秀的闭源模型相当。在3070m生成1920x1088图片，使用Teacache大约要8分钟。使用案例位于 https://willian7004-media-blog.streamlit.app 。

OmniGen部署门槛不高，虽然运行效率比不上主流文生图模型，但在图像编辑模型算是比较好的方案。在3070m生成1080p图片大约要8分钟。

如果侧重速度，可以使用Cosmos Predict2 2b，密集细节表现差一些，在3070m生成1536x1024图片用时74秒。由于光照和速度优势，目前作为主力绘画模型。

其它使用案例：
1. PixelWave Flux.1 dev： https://william7004-new-gallery.streamlit.app/Pixelwave
2. cogview4: https://william7004-gallery.streamlit.app/AI%E5%9B%BE%E7%89%87
3. Hunyuan Video:  https://william7004-hunyuan-video-gallery.streamlit.app/%E5%9B%BE%E7%89%87

##### 移动设备

在安卓设备运行绘画模型建议使用Local Dream，支持骁龙NPU，添加了一些微调模型的支持。使用骁龙8gen1运行Stable Diffusion1.5微调的模型，30步比较合适，大约要18秒，提高到768x768分辨率要61秒，1024x1024分辨率因为容易出现内容重复问题而不建议使用。

具体的模型上，考虑光照和细节表现，目前只保留Absolute Reality。

由于有对内存和速度优化的需求，Local Dream使用fp8激活值和固定分辨率，生成效果比Comfyui差不少。

### 视频模型

闭源视频模型中Veo2和可灵2.0等模型效果好但成本也较高，可灵1.6的成本低一些。

开源视频模型效果最好的是Wan2.1 14b FusionX，整合了速度和画质优化方法，用8步生成视频画质略高于原版。由于显存优化以及对应的速度问题，弃用了WanVideoWrapper节点，官方工作流8g显存能生成45帧1200x672视频，用时11分钟。VACE由于显存和算力需求更高以及搭配FusionX时未解决光照问题，目前已弃用。

如果侧重速度，可以使用LTX Video0.9.6，在3070m生成1088x608分辨率视频单帧时间约1秒。

其它使用案例：
1. Hunyuan Video:  https://william7004-hunyuan-video-gallery.streamlit.app/%E8%A7%86%E9%A2%91
2. Wan2.1 14b： https://william7004-new-gallery.streamlit.app/AI%E8%A7%86%E9%A2%91
3. Wan2.1 1.3b：https://william7004-gallery.streamlit.app/AI%E8%A7%86%E9%A2%91 

### 音频模型

##### TTS模型

由于没有推理框架，我用过的TTS模型不多，目前主要使用Fish Speech，使用案例位于 https://william7004-gallery.streamlit.app/LLM%E6%95%A3%E6%96%87%E9%9B%86

Fish Speech默认设置下运行较慢，使用3070m运行在Windows刚好到实时级别，在Linux约为2倍速。使用torch compile能达到6倍速度但Windows下缺少编译器。

##### 音乐模型

ACE Step是ComfyUI支持的第二个音乐模型，解决了YuE音质差的问题和Diffsynth前后衔接差的问题。使用案例位于 https://willian7004-media-blog.streamlit.app

其它使用案例：\
YuE算是第一个可用的开源音乐模型，逻辑达到可用水平但音质比较差，使用案例位于 https://william7004-gallery.streamlit.app/LLM%E6%9F%A5%E8%AF%A2 