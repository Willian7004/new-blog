# 绘画、视频和TTS模型

### 绘画模型

##### 桌面设备

目前最好的开源绘画模型是HiDream i1 full，细节与优秀的闭源模型相当。在3070m生成1920x1088图片，使用Teacache大约要8分钟。其步数蒸馏版本相比Flux.1也有一定优势。使用案例位于 https://willian7004-media-blog.streamlit.app

OmniGen部署门槛不高，虽然运行效率比不上主流文生图模型，但在图像编辑模型算是比较好的方案。在3070m生成1080p图片大约要8分钟。

如果侧重速度，可以使用Stable Diffusion3搭配Hyper SD 8步lora，人物相比原版有一定改善，在3070m生成1024x1024图片用时6.5秒，对其它分辨率兼容性较差。

其它使用案例：
1. PixelWave Flux.1 dev： https://william7004-new-gallery.streamlit.app/Pixelwave
2. cogview4: https://william7004-gallery.streamlit.app/AI%E5%9B%BE%E7%89%87
3. Hunyuan Video:  https://william7004-hunyuan-video-gallery.streamlit.app/%E5%9B%BE%E7%89%87

##### 移动设备

在安卓设备运行绘画模型建议使用Local Dream，支持骁龙NPU，添加了一些微调模型的支持。使用骁龙8gen1运行Stable Diffusion1.5微调的模型，30步比较合适，大约要18秒，提高到768x768分辨率要61秒，1024x1024分辨率因为容易出现内容重复问题而不建议使用。

具体的模型上，考虑光照和细节表现，目前只保留Absolute Reality。

由于有对内存和速度优化的需求，Local Dream使用fp8激活值和固定分辨率，生成效果比Comfyui差不少。

### 视频模型

闭源视频模型中Veo2和可灵2.0等模型效果好但成本也较高，可灵1.6的成本低一些。

开源视频模型效果最好的是Wan2.1 14b，目前也有Accvid用于加速生成（Wan2.1的Accvid用了10步，应该是比较均衡的方案，Hunyuan Video的5步Accvid和6到8步的FastVideo都有明显画质损失）使用WanVideoWrapper运行时8g显存能生成33帧1152x640视频，用时约10分钟。WanVideoWrapper显存优化比Comfyui官方工作流差，但提供了模块化的VACE模型并且有量化版本，也有Enhance a Video功能用于提高画质。使用VACE模型时8g显存能生成29帧1088x608视频，用时约8分钟。

其它使用案例：
1. Hunyuan Video:  https://william7004-hunyuan-video-gallery.streamlit.app/%E8%A7%86%E9%A2%91
2. Wan2.1 14b： https://william7004-new-gallery.streamlit.app/AI%E8%A7%86%E9%A2%91
3. Wan2.1 1.3b：https://william7004-gallery.streamlit.app/AI%E8%A7%86%E9%A2%91 

### 音频模型

##### TTS模型

由于没有推理框架，我用过的TTS模型不多，目前主要使用Fish Speech，使用案例位于 https://william7004-gallery.streamlit.app/LLM%E6%95%A3%E6%96%87%E9%9B%86

Fish Speech默认设置下运行较慢，使用3070m运行在Windows刚好到实时级别，在Linux约为2倍速。使用torch compile能达到6倍速度但Windows下缺少编译器。

##### 音乐模型

ACE Step是ComfyUI支持的第二个音乐模型，解决了YuE音质差的问题和Diffsynth前后衔接差的问题。使用案例位于 https://willian7004-media-blog.streamlit.app

其它使用案例：\
YuE算是第一个可用的开源音乐模型，逻辑达到可用水平但音质比较差，使用案例位于 https://william7004-gallery.streamlit.app/LLM%E6%9F%A5%E8%AF%A2 