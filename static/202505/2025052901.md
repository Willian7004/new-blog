## Deepseek R1 0528速报以及对新博客的规划

Deepseek R1 0528虽然没有使用新的预训练模型，但由于后训练优化以及对一些新模型进行蒸馏，性能有一定提升。前端编程提升显著，有较好的外观和布局表现。写作任务对提示词遵循度更高，并且可以生成较长的文章。目前官方没有公布完整测试结果，第三方测试有以下表现：
1. 一项three.js测试中，表现优于Claude Sonnet4（参考https://www.zhihu.com/question/1911132833226916938/answer/1911228976870949080）
2. 在一个逻辑和编程测试集中表现在Claude Sonnet4和Gemini2.5 pro 0506之间（参考https://www.zhihu.com/question/1911132833226916938/answer/1911188271691694392）
3. Live Code Bench表现与O4-Mini (Medium)接近。

原本决定月内不更就上Claude4了，这次更新后还是决定继续用开源模型。由于新架构很可能要继续增加参数量，有一个现有架构下性能更高的模型也有利于降低成本，并且与当前的前沿模型差距也比较小。

由于前端能力提升，后续会进行大规模的web程序开发，但博客项目正式迁移到GitHub Pages还需要等待钉子户视频模型，文章会改用Libreoffice Writer实现所见即所得编辑。暂定创建GitHub Pages用于展示html项目。

23点更新：模型卡已发布。

5.30更新：蒸馏版本发布，只有使用Qwen3 8b为底模的版本，性能在Qwen3 32b与235b版本之间，说明了后续8b参数量能实现次旗舰水平。