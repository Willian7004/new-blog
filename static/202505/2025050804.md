## 尝试Unsloth动态量化2.0

Unsloth动态量化2.0能对模型不同层使用不同级别的量化，相比之前的版本添加了对dense模型的支持。理论上MoE模型可用q2量化，dense模型可用q3量化。

之前用ollama部署q3量化的模型无法节省显存，考虑到可能是因为ollama缩减相应功能，使用LM Studio测试了qwen3 14b的IQ3_XXS量化。

测试发现，LM Studio能正确处理q3量化，8g显存可用q8激活值和16k上下文，在3070m上大约30token/s，明显比8b版本的60token/s慢。个人认为q8激活值下推理速度接近显存带宽除以q8量化的模型大小，因此较大的模型速度会明显下降。生成效果方面，主要测试了写作，大约20%的时间为生成思维链起始token，其它时候效果接近更高精度的版本。在agent应用中，可以考虑重新生成无思维链起始token的对话。

在up主“AI超元域”的测试中，Qwen3 14b的能力与32b版本接近，也验证了我之前的猜测。这样的话相当于8g显存能部署次旗舰性能的模型，有较大优势。

更新：Qwen3技术报告发布，包含所有版本模型的测试结果，14b版本除Codeforces外性能均接近32b及30b版本。