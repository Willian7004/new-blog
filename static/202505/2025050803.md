## AI创作周期律

对我个人来说，一类AI模型中有提升较大的新模型，会使我更乐意生成较多内容，而过了一段时间后常因为模型能力瓶颈导致创作减少。

LLM方面，我入坑时算是从预训练过渡到后训练阶段，最早使用的是Qwen1.5，效果不太好就基本不使用了。后面Qwen2和Deepseek Coder v2相继推出，效果有较大提升，就尝试用于不少应用。后面一段时间旗舰模型提升不大，主要是小型化有一定发展，尝试了InternLM2.5、Gemma2和Qwen2.5等本地模型。Deepseek R1推出后意味着开源模型实现推理scaling，各方面能力提升，本地部署7b模型也能达到旗舰非推理模型的推理能力，因此又创作了不少内容以及尝试本地模型。Deepseek R2还是推理scaling，有集束搜索，但推理能力本身提升应该比刚开始实现推理时提升小很多，能实现类似于o4 mini的多步function calling的话也算是有比较大的提升。

绘画模型方面，主要是三个阶段。第一个是传统模型，最早接触的是stable diffusion xl以及turbo版本。第二个是引入DiT以及进一步scaling，包括stable diffusion3 midium和flux.1，提示词理解和生成效果都有明星提升。第三个是增加步数和进一步scaling，其实前段时间的闭源模型有这一类的，但开源模型中第一个做到比较好的是HiDream i1 full。不过绘画模型的问题是对scaling依赖相对较大，虽然有优秀模型但成本也上升了。

视频模型主要是CogVideoX、Hunyuan Video到Wan2.1的提升，架构区别不大，同样存在算力成本上升较多的问题。