## 新的LLM存在的问题

随着推理扩展，LLM还在正常换代。考虑模型和思维链蒸馏，成本也在可控范围，但有一些问题只在比较新的LLM出现。

#### 后训练导致过度结构化和输出多余内容

后训练和对齐较多的模型在各类任务输出偏向结构化，有时候能更全面地回答问题，但在文章总结等任务会导致输出多余内容。qwen2系列的这个问题比较明显，在翻译中也有类似情况，因此我在浏览器翻译插件选择了glm4 9b。在推理模型中，这一问题有明显改善。

#### 强化学习导致幻觉问题

强化学习由于缺乏对奖励方式的优化，存在幻觉但最终解决问题也会认为是优秀的解答，因此导致幻觉率上升，最新的o3和o4mini的这方面问题更加明显，导致涉及事实信息的回答非常不可靠。优化强化学习流程有望解决这一问题。