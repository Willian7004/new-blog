## 吐槽一下Minicpm4与Llama.cpp

Minicpm4虽然在参数稀疏的情况下，非推理测试集中达到同参数量qwen3的水平，但实际生成还是旧模型的风格。如果能集成推理以及多模态并且有能够发挥速度优势的推理框架，在各类无独显设备中有比较好的应用前景。

本次测试使用了以Llama.cpp为后端的LM Studio，推理速度与同参数量dense模型相比没有优势。实际上，根据之前的使用经历，Llama.cpp运行moe模型时只在Qwen系列表现出优势，而之前用过的Deepseek v2 Lite和Ganite 3.1 3b都没有速度优势。