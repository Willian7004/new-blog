## 考虑引入一些免费闭源模型

我在之前的博客项目提到过，考虑到后续对生态的影响，只使用开源模型。硬件方面，除了对推理算力要求较低的LLM有特例外，实施不买N卡、不租N卡的策略（由于AMD的9000系列定价问题，考虑对A卡也。

由于从市场角度讲，AI厂商购买大量计算卡，破坏了硬件行情，因此要求开源作为补偿。但为了获得更直接的补偿，只能使用免费的在线模型，目前引入了Openrouter的免费模型以及Deepseek和Qwen Chat的服务。为了从闭源模型开发方也获得类似补偿，考虑引入一些免费闭源模型。暂时考虑引入豆包，其它的后续再考虑。

6.9更新：豆包的Seedream3.0生成的图片细节并不理想，也缺乏对同一个智能体的多轮对话管理功能，在常规类型中只能作为补充性模型。不过在实时语音和视频分析功能上有一定优势，而通义等应用已经对音频输入功能做了一定限制，后续会继续保留豆包。