## 考虑引入一些免费闭源模型

我在之前的博客项目提到过，考虑到后续对生态的影响，只使用开源模型。硬件方面，除了对推理算力要求较低的LLM有特例外，实施不买N卡、不租N卡的策略（由于AMD的9000系列定价问题，考虑对A卡也。

由于从市场角度讲，AI厂商购买大量计算卡，破坏了硬件行情，因此要求开源作为补偿。但为了获得更直接的补偿，只能使用免费的在线模型，目前引入了Openrouter的免费模型以及Deepseek和Qwen Chat的服务。为了从闭源模型开发方也获得类似补偿，考虑引入一些免费闭源模型。暂时考虑引入豆包，其它的后续再考虑。