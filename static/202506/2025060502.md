## 目前交互式视频模型/世界模型的问题

这类模型称为世界模型有一定歧义，因为可能表示用于机器人的模型。因此我个人习惯称为交互式视频模型。为了评估性能问题，只分析开源模型。

这类模型中，实时级别的有[eloialonso/diamond](https://github.com/eloialonso/diamond)和[etched-ai/open-oasis](https://github.com/etched-ai/open-oasis)。前者部署过，CS:GO版本两个步骤的步数分别设为2步和3步时在3070m上能实时运行，后者用过官方demo。这个级别的参数量较小，场景记忆表现差，存在距离墙壁或纯色场景较近时容易造成生成异常以及画质问题。

中间级别包含[microsoft/mineworld](https://github.com/microsoft/mineworld)，速度慢一些但准确度达到可用水平。在3070m生成速度约为每秒1帧，同分辨率下速度不及LTX Video 0.9.6。由于没有其它可参考模型，只分析该模型。缺点是缺乏对不同帧率和生成长度的适配导致只能输入操作生成视频片段，以及只能适配特定游戏。

离线级别有[SkyworkAI/Matrix-Game](https://github.com/SkyworkAI/Matrix-Game)，以Hunyuan Video为底模，主要在Minecraft的数据训练但也支持输入任意图片作为起始图片。虽然这一模型现在基本不可能实现实时推理，但说明可以把常规的视频模型转为交互式模型。如果把LTX Video 0.9.6作为底模，速度可以上升到中间级别，用8步版本还要快一些，不过这两个模型作为底模时容易出现长时间生成质量下降的问题。