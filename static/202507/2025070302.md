## 摆脱LLM焦虑

我之前存在过度关注AI模型的问题，主要是希望新的模型能带来提升。现在不少领域模型进入成熟阶段，绘画/视频方面也有合适的端侧模型，关注点就集中在LLM上。

LLM除了旗舰模型的发展外，比较重要的问题还包括小型次旗舰模型、用于CPU推理的MoE模型和用于手机的小型MoE模型，后者允许比次旗舰模型低一个级别。

次旗舰模型方面，qwen3基本推进到30b MoE而14b Dense接近次旗舰级别，参考Deepseek R1 0528 Qwen3 8b和Ring Lite的进展，qwen3.5有望推进到16b MoE次旗舰而8b Dense接近次旗舰，这样的话就满足了8g显卡和CPU的部署需求。

在手机上，受内存容量和带宽限制，需要更小的MoE模型，而Ring Lite的规模无法适用于相对常见的12g机型。在这方面比较有希望的是MiniCPM4 8b，可用于12g内存的设备，不过要达到实用水平还是要等待多模态和推理版本。

面壁定律指出LLM知识密度每8个月翻倍。从之前的模型看，qwen1.5到2.5过程中次旗舰模型从72b缩小到32b，而qwen3开始推出次旗舰MoE也适用于这一定律。据此推测，8b MoE正式进入次旗舰级别还需等待qwen4.5，因此MiniCPM4这一代只能做到低于次旗舰，但在手机上算比较实用了。